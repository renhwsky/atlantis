---
layout: post
title:  CephFS灾难恢复
date: 2019-05-27
categories: 分布式文件系统 备份 恢复
tags: 文件系统
excerpt: CephFS灾难恢复
---

前言
------

  存储最为重要的特点是稳定性和安全性，而数据的安全又排在首位，对应CephFS分布式文件系统而言，
除rados的副本策略外，它本身并没有额外的备份策略，因此一旦文件系统有异常，包括使用
ceph fs rm删除文件系统，或者删除了meta元数据池中的对象时（ceph集群还是正常运行）则CephFS
的目录结构和目录对象将无法正常获取到，导致数据无法使用。下面我们将针对以上这种情况进行如下2种方式
的恢复：

方案1：使用meta元数据池快照和元数据对象名称来恢复
------

（1）前提条件是已经创建好元数据池metadata和数据池data，并使用ceph fs new创建文件系统cephfs        
（2）对元数据池meta进行pool级别的快照：    
    示例：rados -p metadata rollback meta_snap-1       
（3）保存metadata中对象信息
    示例：for a in `rados -p metedata ls`; do echo $a >> list.txt;done;     
（4）删除cephfs文件系统，或者删除metadata中的元数据对象       
    示例：ceph fs rm cephfs --yes-i-really-mean-it       
    or   for a in  `rados -p metadata ls`; do rados -p metadata rm $a;done;     
（5）重新创建新的元数据存储池metadata2,或者在原metadata使用-force强制创建(不推荐)
    示例：ceph fs new cephfs metedata2 data      
    or    ceph fs new cephfs metadata data --force
（6）快照回归操作
    示例： for a in `cat list.txt`;do rados -p meta rollback $a meta_snap-1;done;    
（7）重新mds和重新挂载cephfs客户端后恢复成功         

方案2：使用data数据池来恢复
------

（1）前提条件是已经创建好元数据池metadata和数据池data，并使用ceph fs new创建文件系统cephfs    
（2）删除cephfs文件系统，或者删除metadata中的元数据对象       
    示例：ceph fs rm cephfs --yes-i-really-mean-it       
    or   for a in  `rados -p metadata ls`; do rados -p metadata rm $a;done;    
（3）创建一个新元数据池metadata2   
（4）开启支持多文件系统功能 ceph fs flag set enable_multiple true --yes-i-really-mean-it    
（5）将新创建的元数据池与老的data数据池关联起来    
    示例：ceph fs new cephfs2 metadata2 data --allow-dangerous-metadata-overlay    
（6）初始化新文件系统操作   
    cephfs-data-scan init --force-init --filesystem cephfs2 --alternate-pool metadata2    
    ceph fs reset recovery-fs --yes-i-really-mean-it     
    cephfs-table-tool cephfs2:all reset session    
    cephfs-table-tool cephfs2:all reset snap    
    cephfs-table-tool cephfs2:all reset inode    
 （7）恢复操作
    cephfs-data-scan scan_extents --force-pool --alternate-pool metadata2 --filesystem cephfs  data   
    cephfs-data-scan scan_inodes --alternate-pool metadata2 --filesystem cephfs --force-corrupt --force-init 
    data     
    cephfs-data-scan scan_links --filesystem cephfs      
    systemctl start ceph-mds@sky     
    ceph daemon mds.sky scrub_path / recursive repair       
 （8）设置默认的cephfs文件系统名称    
    ceph fs set-default cephfs2    
 （9）重新挂载，查看数据       
    数据在lost+found下，但已经没有目录结构，除非之前备份了ceph daemon mds.lab102 dump cache目录结构，否则很难知道     数据的目录结构   
