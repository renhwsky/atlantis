---
layout: post
title:   GlusterFS介绍
date: 2019-04-28
categories: 分布式文件系统
tags: 文件系统
excerpt: 文件系统基本概念
---

前言
------


GlusterFS特性介绍
------
1. Cache一致性实现
   GlusterFS对于客户端Cache实现比较简单，它只实现了客户端的读Cache，没有实现客户端的写Cache功能,并且读Cache
   也只实现了弱一致性功能，没有像Ceph实现了强一致性。其GlusterFS的客户端缓存是基于设置的缓存有效时间来进行重新
   获取，其实现方式为：客户端缓存会周期性的去服务端获取文件最后修改时间，如果当前缓存的修改时间小于获取文件最后
   修改时间，则将置其缓存数据无效，下次获取数据时去服务端获取。默认客户端缓存刷新时间为1s，如果在多个客户端同时
   读写时，将会导致某个客户端写入的数据，并没有被另一个客户端实时读取上来，最终导致其客户端之间看到的数据并不是
   一致的。我们需要从应用层面考虑这种弱一致是否能接受，如果不能接受，则需要考虑关闭GlusterFS的读缓存功能，当然
   这样会影响到GlusterFS的整体性能表现。

2. 元数据功能和性能
   GlusterFS的核心思想和Ceph类似，也是基于DHT（Distributed Hash Table）来实现文件查找定位，DHT的特点是通过
   计算的方式来进行查找，而非通过中心化的普通查表方式，这样规避查表方式出现热点场景，理论上实现了无限Scale out
   横向扩展能力。通过文件系统提供的路径和名称，就可以通过定位到文件存放位置，但这种方式也有一个致命的缺点，就是
   对有大量文件的目录进行ls和rm操作时，会非常缓慢，因为文件会分布到集群中的所有位置，并且还需要组合目录属性结构，
   其查询速度和中心化的普通查表方式差不多。当然CephFS在使用时也有类似的问题，我们一般通过合理的构建目录层级结构
   来最大效率的规避这类问题，另外可以增大缓存大小，使用更好的网络适配器和更高频率的CPU资源,使用SSD硬盘来存储元
   数据资源。
   
3. 小文件问题
   GlusterFS主要应用场景是大文件系统，对于小文件，尤其是海量小文件LOSF（lots of small file）应用并不太好，其实
   LOSF的问题是工业界和学术界公认的难题，GlusterFS做为分布式文件系统，并没有对小文件读写进行特殊优化处理，所以
   性能也不太好。对应小文件应用场景，OPS是关键性能衡量指标，造成性能和存储效率低下的主要原因包括元数据管理、数据
   布局方式、IO处理流程、Cache实现和网络开销等方面。从理论上分析，对应LOSF场景来说，要想提高其性能，则应该从元
   数据管理、缓存机制和合并小文件等方面展开，而且优化时一个系统工程，结合硬件、软件从多个层面同时着手，优化效果
   会更显著。
   
4. 集群集中式管理
   在GlusterFS早期的版本中,没有中心化的管理组件存在，各节点之间完全对等。集群的配置信息在所有的节点之间进行同步，
   配置信息在各节点上都有，好处是配置信息可以直接在本地查找，坏处是在集群规模比较大的情况下，会出现配置信息在各
   节点之间无序的进行更新，不但效率低下，而且存在一致性问题。在GlusterFS后期的版本中增加了glusterd组件来实现集群
   集中式管理.Ceph则是通过Mon和Mgr来进行集群集中式管理。
   
5. GlusterFS的数据分布方式、负载方式和高可靠问题
   数据平衡
   GlusterFS的hash分布是以目录为基本单位，文件的父目录利用扩展属性记录子目录的映射信息，子文件在父目录所属存储服务
   器中进行分布，由于文件目录事先保存了分布信息，因此新增节点不会影响现有文件存储分布，它将从此后的新创建目录开始参
   与存储分布调度。这种设计，新增节点不需要移动任何文件，但是负载均衡没有平滑处理，老节点负载较重。GlusterFS实现了
   容量负载均衡功能，可以对已经存在的目录文件进行Rebalance，使得早先创建的老目录可以在新增存储节点上分布，并可对现
   有文件数据进行迁移实现容量负载均衡。当然在实际应用中，这种迁移的方式有各种各样的问题，比如hash存取数据方式，在进
   行重平衡时，会导致大量的数据迁移（Ceph也有类似的问题），当然手工开启平衡模式的方式也不够智能，需要人工来判断是否
   需要进行数据平衡。
   数据分布
   GlusterFS有三种基本集群模式，即分布式集群、条带集群和复制集群，且三种方式可以叠加.对于分布式集群，文件
   通过HASH算法分散到集群节点上，访问时使用HASH算法进行查找定位。复制集群类似RAID1，所有节点数据完全相同，访问时可
   以选择任意个节点。条带集群与RAID0相似，文件被分成数据块以Round Robin方式分布到所有节点上，访问时根据位置信息确定
   节点。条带模式是目前最不成熟的方式，其性能比较差。
   高可靠
   GlusterFS有2种类型的副本备份方式，一种是hash复制卷，一种是简单复制卷。副本数越多，文件的可靠性就越高，但是副本数
   越多，也意味着存储利用率低，且写性能越差。使用EC纠删码则可以提高存储的利用率。是一种除副本模式外的另外一种比较好的
   高可靠模式。

6. 数据安全
   GlusterFS的后面使用的文件系统是EXT4、XFS和ZFS存储系统，其实现方式是将一个前端大文件切分为多个后端小文件（存储在
   EXT、XFS或者ZFS文件系统之上），且这些文件可直接被访问其他工具直接访问，其数据信息容易被保留出去。
   当然解决方案是：通过增加第三方的加密硬盘的方式，或者使用GlusterFS私有的格式（比如Ceph使用自有的bluestore文件系统）
