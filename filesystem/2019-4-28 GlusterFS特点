---
layout: post
title:   GlusterFS介绍
date: 2019-04-28
categories: 分布式文件系统
tags: 文件系统
excerpt: 文件系统基本概念
---

前言
------


GlusterFS特性介绍
------
1. Cache一致性实现
   GlusterFS对于客户端Cache实现比较简单，它只实现了客户端的读Cache，没有实现客户端的写Cache功能,并且读Cache
   也只实现了弱一致性功能，没有像Ceph实现了强一致性。其GlusterFS的客户端缓存是基于设置的缓存有效时间来进行重新
   获取，其实现方式为：客户端缓存会周期性的去服务端获取文件最后修改时间，如果当前缓存的修改时间小于获取文件最后
   修改时间，则将置其缓存数据无效，下次获取数据时去服务端获取。默认客户端缓存刷新时间为1s，如果在多个客户端同时
   读写时，将会导致某个客户端写入的数据，并没有被另一个客户端实时读取上来，最终导致其客户端之间看到的数据并不是
   一致的。我们需要从应用层面考虑这种弱一致是否能接受，如果不能接受，则需要考虑关闭GlusterFS的读缓存功能，当然
   这样会影响到GlusterFS的整体性能表现。

2. 元数据功能和性能
   GlusterFS的核心思想和Ceph类似，也是基于DHT（Distributed Hash Table）来实现文件查找定位，DHT的特点是通过
   计算的方式来进行查找，而非通过中心化的普通查表方式，这样规避查表方式出现热点场景，理论上实现了无限Scale out
   横向扩展能力。通过文件系统提供的路径和名称，就可以通过定位到文件存放位置，但这种方式也有一个致命的缺点，就是
   对有大量文件的目录进行ls和rm操作时，会非常缓慢，因为文件会分布到集群中的所有位置，并且还需要组合目录属性结构，
   其查询速度和中心化的普通查表方式差不多。当然CephFS在使用时也有类似的问题，我们一般通过合理的构建目录层级结构
   来最大效率的规避这类问题，另外可以增大缓存大小，使用更好的网络适配器和更高频率的CPU资源,使用SSD硬盘来存储元
   数据资源。
   
3. 小文件问题
   GlusterFS主要应用场景是大文件系统，对于小文件，尤其是海量小文件LOSF（lots of small file）应用并不太好，其实
   LOSF的问题是工业界和学术界公认的难题，GlusterFS做为分布式文件系统，并没有对小文件读写进行特殊优化处理，所以
   性能也不太好。对应小文件应用场景，OPS是关键性能衡量指标，造成性能和存储效率低下的主要原因包括元数据管理、数据
   布局方式、IO处理流程、Cache实现和网络开销等方面。从理论上分析，对应LOSF场景来说，要想提高其性能，则应该从元
   数据管理、缓存机制和合并小文件等方面展开，而且优化时一个系统工程，结合硬件、软件从多个层面同时着手，优化效果
   会更显著。
   
4. 集群集中式管理
   在GlusterFS早期的版本中,没有中心化的管理组件存在，各节点之间完全对等。集群的配置信息在所有的节点之间进行同步，
   配置信息在各节点上都有，好处是配置信息可以直接在本地查找，坏处是在集群规模比较大的情况下，会出现配置信息在各
   节点之间无序的进行更新，不但效率低下，而且存在一致性问题。在GlusterFS后期的版本中增加了glusterd组件来实现集群
   集中式管理.Ceph则是通过Mon和Mgr来进行集群集中式管理。
   

